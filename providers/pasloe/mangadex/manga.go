package mangadex

import (
	"fmt"
	"github.com/Fesaa/Media-Provider/comicinfo"
	"github.com/Fesaa/Media-Provider/db/models"
	"github.com/Fesaa/Media-Provider/http/payload"
	"github.com/Fesaa/Media-Provider/http/wisewolf"
	"github.com/Fesaa/Media-Provider/log"
	"github.com/Fesaa/Media-Provider/providers/pasloe/api"
	"github.com/Fesaa/Media-Provider/utils"
	mapset "github.com/deckarep/golang-set/v2"
	"io"
	"log/slog"
	"net/http"
	"os"
	"path"
	"regexp"
	"slices"
	"strconv"
	"strings"
	"time"
)

const comicInfoNote = "This comicinfo.xml was auto generated by Media-Provider, with information from mangadex. Source code can be found here: https://github.com/Fesaa/Media-Provider/"

var volumeRegex = regexp.MustCompile(".* Vol\\. (\\d+).cbz")
var chapterRegex = regexp.MustCompile(".* Ch\\. (\\d+).cbz")

func NewManga(req payload.DownloadRequest, client api.Client) api.Downloadable {
	block := &manga{
		id:             req.Id,
		volumeMetadata: make([]string, 0),
	}
	d := api.NewDownloadableFromBlock[ChapterSearchData](req, block, client)
	block.DownloadBase = d
	return block
}

type manga struct {
	*api.DownloadBase[ChapterSearchData]
	id string

	info     *MangaSearchData
	chapters ChapterSearchResponse

	coverFactory   CoverFactory
	volumeMetadata []string

	totalVolumes     int
	foundLastVolume  bool
	foundLastChapter bool
}

func (m *manga) Title() string {
	if m.info == nil {
		return m.id
	}

	return m.info.Attributes.EnTitle()
}

func (m *manga) Provider() models.Provider {
	return m.Req.Provider
}

func (m *manga) LoadInfo() chan struct{} {
	out := make(chan struct{})
	go func() {
		mangaInfo, err := GetManga(m.id)
		if err != nil {
			m.Log.Error("error while loading manga info", "err", err)
			m.Cancel()
			return
		}
		m.info = &mangaInfo.Data

		chapters, err := GetChapters(m.id)
		if err != nil || chapters == nil {
			m.Log.Error("error while loading manga chapters", "err", err)
			m.Cancel()
			return
		}
		m.chapters = chapters.FilterOneEnChapter()

		volumes := mapset.NewSet[string]()
		m.foundLastVolume = false
		for _, ch := range m.chapters.Data {
			if ch.Attributes.Volume == m.info.Attributes.LastVolume && m.info.Attributes.LastVolume != "" {
				m.foundLastVolume = true
			}
			if ch.Attributes.Chapter == m.info.Attributes.LastChapter && m.info.Attributes.LastChapter != "" {
				m.foundLastChapter = true
			}

			// We don't want to add chapters not belonging to a volume in this count
			// A series may have specials, this doesn't change the volume count
			if _, err = strconv.ParseInt(ch.Attributes.Volume, 10, 64); err == nil {
				volumes.Add(ch.Attributes.Volume)
			} else {
				m.Log.Trace("not adding chapter, as Volume string isn't an int",
					slog.String("volume", ch.Attributes.Volume),
					slog.String("chapter", ch.Attributes.Chapter),
				)
			}
		}
		m.totalVolumes = volumes.Cardinality()

		covers, err := GetCoverImages(m.id)
		if err != nil || covers == nil {
			m.Log.Warn("error while loading manga coverFactory, ignoring", "err", err)
			m.coverFactory = func(volume string) (string, bool) {
				return "", false
			}
		} else {
			m.coverFactory = covers.GetCoverFactory(m.id)
		}

		close(out)
	}()
	return out
}

func (m *manga) All() []ChapterSearchData {
	return m.chapters.Data
}

func (m *manga) GetInfo() payload.InfoStat {
	volumeDiff := m.ImagesDownloaded - m.LastRead
	timeDiff := max(time.Since(m.LastTime).Seconds(), 1)
	speed := max(int64(float64(volumeDiff)/timeDiff), 1)
	m.LastRead = m.ImagesDownloaded
	m.LastTime = time.Now()

	return payload.InfoStat{
		Provider: models.MANGADEX,
		Id:       m.id,
		Name: func() string {
			title := m.Title()
			if title == m.id && m.TempTitle != "" {
				return m.TempTitle
			}
			return title
		}(),
		Size:        strconv.Itoa(len(m.ToDownload)) + " Chapters",
		Downloading: m.Wg != nil,
		Progress:    utils.Percent(int64(m.ContentDownloaded), int64(len(m.ToDownload))),
		SpeedType:   payload.IMAGES,
		Speed:       payload.SpeedData{T: time.Now().Unix(), Speed: speed},
		DownloadDir: m.GetDownloadDir(),
	}
}

func (m *manga) ContentDir(chapter ChapterSearchData) string {
	if m.totalVolumes == 0 {
		return m.chapterDir(chapter)
	}
	return m.volumeDir(chapter.Attributes.Volume)
}

func (m *manga) ContentPath(chapter ChapterSearchData) string {
	return m.chapterPath(chapter)
}

func (m *manga) ContentKey(chapter ChapterSearchData) string {
	return chapter.Id
}

func (m *manga) ContentLogger(chapter ChapterSearchData) *log.Logger {
	return m.Log.With("id", chapter.Id, "chapterTitle", chapter.Attributes.Title)
}

func (m *manga) ContentUrls(chapter ChapterSearchData) ([]string, error) {
	imageInfo, err := GetChapterImages(chapter.Id)
	if err != nil {
		return nil, err
	}
	return imageInfo.FullImageUrls(), nil
}

func (m *manga) WriteContentMetaData(chapter ChapterSearchData) error {
	metaKey, metaPath := func() (string, string) {
		if m.totalVolumes == 0 {
			return chapter.Attributes.Chapter, m.chapterPath(chapter)
		}
		return chapter.Attributes.Volume, m.volumePath(chapter)
	}()

	if slices.Contains(m.volumeMetadata, metaKey) {
		m.Log.Trace("volume metadata already written, skipping", "volume", chapter.Attributes.Volume, "chapter", chapter.Attributes.Chapter)
		return nil
	}

	err := os.MkdirAll(metaPath, 0755)
	if err != nil {
		return err
	}

	coverUrl, ok := m.coverFactory(chapter.Attributes.Volume)
	if !ok {
		m.Log.Debug("unable to find cover", "metaKey", metaKey)
	} else {
		m.Log.Trace("downloading cover image", "metaKey", metaKey, "url", coverUrl)
		// Use !0000 cover.jpg to make sure it's the first file in the archive, this causes it to be read
		// first by most readers, and in particular, kavita.
		filePath := path.Join(metaPath, "!0000 cover.jpg")
		if err = downloadAndWrite(coverUrl, filePath); err != nil {
			return err
		}
	}

	m.Log.Trace("writing comicinfoxml", "metaKey", metaKey)
	if err = comicinfo.Save(m.comicInfo(chapter), path.Join(metaPath, "comicinfo.xml")); err != nil {
		return err
	}

	m.volumeMetadata = append(m.volumeMetadata, metaKey)
	return nil
}

func (m *manga) comicInfo(chapter ChapterSearchData) *comicinfo.ComicInfo {
	ci := comicinfo.NewComicInfo()

	ci.Series = m.info.Attributes.EnTitle()
	ci.Year = m.info.Attributes.Year
	ci.Summary = utils.MdToSafeHtml(m.info.Attributes.EnDescription())
	ci.Manga = comicinfo.MangaYes
	ci.AgeRating = m.info.Attributes.ContentRating.ComicInfoAgeRating()
	ci.Web = strings.Join(m.info.FormattedLinks(), ",")

	// Chapter cbz's include title
	if m.totalVolumes == 0 {
		ci.Title = chapter.Attributes.Title
	}

	alts := m.info.Attributes.EnAltTitles()
	if len(alts) > 0 {
		ci.LocalizedSeries = alts[0]
	}

	// Add the comicinfo#count field if the manga has completed, so Kavita can add the correct Completed marker
	// We can't add it for others, as mangadex is community sourced, so may lag behind. But this should be correct
	if m.info.Attributes.Status == StatusCompleted {
		if m.foundLastChapter && m.foundLastVolume {
			ci.Count = m.totalVolumes
		} else {
			m.Log.Warn("Series ended, but not all chapters could be downloaded or last volume isn't present. English ones missing?",
				slog.String("lastChapter", m.info.Attributes.LastChapter),
				slog.Bool("foundLastChapter", m.foundLastChapter),
				slog.String("lastVolume", m.info.Attributes.LastVolume),
				slog.Bool("foundLastVolume", m.foundLastVolume))
		}
	}

	if v, err := strconv.Atoi(chapter.Attributes.Volume); err == nil {
		ci.Volume = v
	} else {
		m.Log.Trace("unable to parse volume number", "volume", chapter.Attributes.Volume, "err", err)
	}

	ci.Genre = strings.Join(utils.MaybeMap(m.info.Attributes.Tags, func(t TagData) (string, bool) {
		n, ok := t.Attributes.Name["en"]
		if !ok {
			return "", false
		}

		if t.Attributes.Group != "genre" {
			return "", false
		}

		return n, true
	}), ",")

	ci.Tags = strings.Join(utils.MaybeMap(m.info.Attributes.Tags, func(t TagData) (string, bool) {
		n, ok := t.Attributes.Name["en"]
		if !ok {
			return "", false
		}

		if t.Attributes.Group == "genre" {
			return "", false
		}

		return n, true
	}), ",")

	ci.Writer = strings.Join(m.info.Authors(), ",")
	ci.Colorist = strings.Join(m.info.Artists(), ",")

	ci.Notes = comicInfoNote
	return ci
}

func (m *manga) DownloadContent(page int, chapter ChapterSearchData, url string) error {
	//m.log.Trace("downloading image", "chapter", chapter.Attributes.Chapter, "url", url)
	filePath := path.Join(m.chapterPath(chapter), fmt.Sprintf("page %s.jpg", utils.PadInt(page, 4)))
	if err := downloadAndWrite(url, filePath); err != nil {
		return err
	}
	m.ImagesDownloaded++
	return nil
}

func (m *manga) ContentRegex() *regexp.Regexp {
	if m.totalVolumes == 0 {
		return chapterRegex
	}
	return volumeRegex
}

func (m *manga) mangaPath() string {
	return path.Join(m.Client.GetBaseDir(), m.GetBaseDir(), m.Title())
}

func (m *manga) volumeDir(v string) string {
	if v == "" {
		return fmt.Sprintf("%s Special", m.Title())
	}

	return fmt.Sprintf("%s Vol. %s", m.Title(), v)
}

func (m *manga) volumePath(chapter ChapterSearchData) string {
	// Download as chapters, if the manga does not have any volumes
	if m.totalVolumes == 0 {
		return m.mangaPath()
	}
	return path.Join(m.mangaPath(), m.volumeDir(chapter.Attributes.Volume))
}

func (m *manga) chapterDir(chapter ChapterSearchData) string {
	if chpt, err := strconv.ParseFloat(chapter.Attributes.Chapter, 32); err == nil {
		chDir := fmt.Sprintf("%s Ch. %s", m.Title(), utils.PadFloat(chpt, 4))
		return chDir
	} else if chapter.Attributes.Chapter != "" { // Don't warm for empty chpt. They're expected to fail
		m.Log.Warn("unable to parse chpt number, not padding", "chapter", chapter.Attributes.Chapter, "err", err)
	}

	return fmt.Sprintf("%s Ch. %s", m.Title(), chapter.Attributes.Chapter)
}

func (m *manga) chapterPath(chapter ChapterSearchData) string {
	return path.Join(m.volumePath(chapter), m.chapterDir(chapter))
}

func downloadAndWrite(url string, path string, tryAgain ...bool) error {
	resp, err := wisewolf.Client.Get(url)
	if err != nil {
		return err
	}

	if resp.StatusCode != http.StatusOK {
		if resp.StatusCode != http.StatusTooManyRequests {
			return fmt.Errorf("bad status: %s", resp.Status)
		}

		retryAfter := resp.Header.Get("X-RateLimit-Retry-After")
		if retryAfter == "" {
			return fmt.Errorf("bad status: %s", resp.Status)
		}

		if unix, err := strconv.ParseInt(retryAfter, 10, 64); err == nil {
			t := time.Unix(unix, 0)

			if len(tryAgain) > 0 && !tryAgain[0] {
				log.Error("Reached rate limit, after sleeping. What is going on?")
				return fmt.Errorf("bad status: %s", resp.Status)
			}

			d := time.Until(t)
			log.Warn("Hit rate limit, try again after it's over",
				slog.String("retryAfter", retryAfter),
				slog.Duration("sleeping_for", d))

			time.Sleep(d)
			return downloadAndWrite(url, path, false)
		}

	}

	defer func(Body io.ReadCloser) {
		if err = Body.Close(); err != nil {
			log.Warn("error while closing response body", "err", err)
		}
	}(resp.Body)
	data, err := io.ReadAll(resp.Body)
	if err != nil {
		return err
	}

	if err = os.WriteFile(path, data, 0755); err != nil {
		return err
	}

	return nil
}
